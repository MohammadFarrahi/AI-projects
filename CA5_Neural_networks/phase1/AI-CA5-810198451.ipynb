{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI - CA5 - FeedForward NN - Mohammad Farrahi 810198451"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import PIL.Image as PilImg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_images = list()\n",
    "for filename in listdir('data'):\n",
    "\timg_data = (int(filename.split('.')[0]), np.asarray(PilImg.open('data/' + filename).convert(mode='L')))\n",
    "\tloaded_images.append(img_data)\n",
    "\n",
    "loaded_images.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing features and labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PX0</th>\n",
       "      <th>PX1</th>\n",
       "      <th>PX2</th>\n",
       "      <th>PX3</th>\n",
       "      <th>PX4</th>\n",
       "      <th>PX5</th>\n",
       "      <th>PX6</th>\n",
       "      <th>PX7</th>\n",
       "      <th>PX8</th>\n",
       "      <th>PX9</th>\n",
       "      <th>...</th>\n",
       "      <th>PX1014</th>\n",
       "      <th>PX1015</th>\n",
       "      <th>PX1016</th>\n",
       "      <th>PX1017</th>\n",
       "      <th>PX1018</th>\n",
       "      <th>PX1019</th>\n",
       "      <th>PX1020</th>\n",
       "      <th>PX1021</th>\n",
       "      <th>PX1022</th>\n",
       "      <th>PX1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>137</td>\n",
       "      <td>141</td>\n",
       "      <td>131</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>136</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>143</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147</td>\n",
       "      <td>171</td>\n",
       "      <td>169</td>\n",
       "      <td>173</td>\n",
       "      <td>201</td>\n",
       "      <td>212</td>\n",
       "      <td>196</td>\n",
       "      <td>135</td>\n",
       "      <td>119</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>152</td>\n",
       "      <td>125</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>123</td>\n",
       "      <td>134</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>148</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>82</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PX0  PX1  PX2  PX3  PX4  PX5  PX6  PX7  PX8  PX9  ...  PX1014  PX1015  \\\n",
       "0   33   34   41   75   76   43   42   56   70   77  ...     120     113   \n",
       "1  124  103   93   99  101  136  171  170  143   93  ...     107     108   \n",
       "2  147  171  169  173  201  212  196  135  119  133  ...     155     152   \n",
       "3  203  200  200  201  201  201  202  202  202  202  ...     153     148   \n",
       "4  105  135  145  130   82   55   48   52   52   53  ...      70      70   \n",
       "\n",
       "   PX1016  PX1017  PX1018  PX1019  PX1020  PX1021  PX1022  PX1023  \n",
       "0     137     141     131     150     153     128     126     123  \n",
       "1     110     112     114     116     118     121     120     121  \n",
       "2     125      76      70     123     134     132     133     135  \n",
       "3     145     146     146     145     139     139     140     138  \n",
       "4      65      62      64      58      55      48      48      50  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_arr_size = loaded_images[0][1].shape[0]*loaded_images[0][1].shape[1]\n",
    "df = pd.DataFrame([img[1].flatten() % 256 for img in loaded_images],\n",
    "                    columns=['PX'+str(i) for i in range(sample_arr_size)],\n",
    "                    \n",
    "    )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   8  horse\n",
       "1  10    cat\n",
       "2  12  horse\n",
       "3  13  horse\n",
       "4  18    cat"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PORTION = 0.22\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=TEST_PORTION, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Showing random image from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range of pixel values: 41 to 237\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_img = loaded_images[y_train.sample().index[0]][1]\n",
    "plt.imshow(random_img, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('A random picture')\n",
    "print('range of pixel values:', random_img.min(), 'to', random_img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically, range of pixel values are [0, 255]. In this particular image, the range of pixel values are shown in plot and max-min values are printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Showing random image from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic_classes = ['cat', 'horse']\n",
    "fig, axes = plt.subplots(1, len(pic_classes), figsize =(6,3))\n",
    "for ind, pic_class in enumerate(pic_classes):\n",
    "    axes[ind].imshow(loaded_images[y_train[y_train['label'] == pic_class].sample().index[0]][1], cmap='gray')\n",
    "    axes[ind].set_title(pic_class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) Size of samples for each class in train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures for each class in train and test data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize =(16,8))\n",
    "\n",
    "axes[0].bar(pic_classes, [y_train[y_train['label'] == pic_class].shape[0] for pic_class in pic_classes])\n",
    "axes[1].bar(pic_classes, [y_test[y_test['label'] == pic_class].shape[0] for pic_class in pic_classes])\n",
    "axes[0].set_title('Train data')\n",
    "axes[1].set_title('Test data')\n",
    "print('Number of pictures for each class in train and test data:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the number of samples for each class in train and test data. It's look like in both train and test dataset, samples devided fairly enough between two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4) Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PX0</th>\n",
       "      <th>PX1</th>\n",
       "      <th>PX2</th>\n",
       "      <th>PX3</th>\n",
       "      <th>PX4</th>\n",
       "      <th>PX5</th>\n",
       "      <th>PX6</th>\n",
       "      <th>PX7</th>\n",
       "      <th>PX8</th>\n",
       "      <th>PX9</th>\n",
       "      <th>...</th>\n",
       "      <th>PX1014</th>\n",
       "      <th>PX1015</th>\n",
       "      <th>PX1016</th>\n",
       "      <th>PX1017</th>\n",
       "      <th>PX1018</th>\n",
       "      <th>PX1019</th>\n",
       "      <th>PX1020</th>\n",
       "      <th>PX1021</th>\n",
       "      <th>PX1022</th>\n",
       "      <th>PX1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.321569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.737255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.192157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8330</th>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.349020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.815686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.474510</td>\n",
       "      <td>0.462745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.639216</td>\n",
       "      <td>0.690196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7800 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PX0       PX1       PX2       PX3       PX4       PX5       PX6  \\\n",
       "5916  0.066667  0.066667  0.039216  0.035294  0.043137  0.043137  0.043137   \n",
       "5129  0.376471  0.372549  0.368627  0.352941  0.349020  0.341176  0.349020   \n",
       "8334  0.219608  0.211765  0.200000  0.196078  0.196078  0.196078  0.196078   \n",
       "1918  0.364706  0.435294  0.470588  0.415686  0.337255  0.345098  0.380392   \n",
       "8330  0.356863  0.384314  0.360784  0.325490  0.337255  0.329412  0.325490   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5734  0.654902  0.749020  0.752941  0.780392  0.819608  0.835294  0.815686   \n",
       "5191  0.149020  0.156863  0.156863  0.160784  0.164706  0.164706  0.164706   \n",
       "5390  0.439216  0.356863  0.305882  0.278431  0.247059  0.215686  0.200000   \n",
       "860   0.639216  0.580392  0.513725  0.576471  0.615686  0.737255  0.800000   \n",
       "7270  0.337255  0.333333  0.360784  0.658824  0.403922  0.321569  0.403922   \n",
       "\n",
       "           PX7       PX8       PX9  ...    PX1014    PX1015    PX1016  \\\n",
       "5916  0.050980  0.047059  0.035294  ...  0.047059  0.274510  0.439216   \n",
       "5129  0.364706  0.380392  0.415686  ...  0.619608  0.698039  0.682353   \n",
       "8334  0.196078  0.196078  0.196078  ...  0.172549  0.176471  0.180392   \n",
       "1918  0.360784  0.333333  0.349020  ...  0.419608  0.423529  0.388235   \n",
       "8330  0.341176  0.321569  0.301961  ...  0.305882  0.345098  0.313725   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5734  0.784314  0.717647  0.545098  ...  0.239216  0.321569  0.470588   \n",
       "5191  0.164706  0.164706  0.168627  ...  0.266667  0.290196  0.309804   \n",
       "5390  0.188235  0.176471  0.164706  ...  0.670588  0.658824  0.643137   \n",
       "860   0.619608  0.313725  0.262745  ...  0.611765  0.545098  0.462745   \n",
       "7270  0.560784  0.545098  0.435294  ...  0.662745  0.666667  0.647059   \n",
       "\n",
       "        PX1017    PX1018    PX1019    PX1020    PX1021    PX1022    PX1023  \n",
       "5916  0.286275  0.149020  0.070588  0.196078  0.200000  0.278431  0.321569  \n",
       "5129  0.666667  0.709804  0.686275  0.615686  0.701961  0.725490  0.737255  \n",
       "8334  0.180392  0.184314  0.184314  0.184314  0.188235  0.192157  0.192157  \n",
       "1918  0.400000  0.419608  0.435294  0.443137  0.443137  0.435294  0.439216  \n",
       "8330  0.270588  0.294118  0.215686  0.247059  0.313725  0.309804  0.349020  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5734  0.498039  0.513725  0.466667  0.388235  0.258824  0.141176  0.058824  \n",
       "5191  0.305882  0.290196  0.270588  0.313725  0.572549  0.792157  0.815686  \n",
       "5390  0.611765  0.552941  0.545098  0.525490  0.505882  0.474510  0.462745  \n",
       "860   0.498039  0.447059  0.450980  0.439216  0.439216  0.478431  0.466667  \n",
       "7270  0.686275  0.647059  0.615686  0.627451  0.623529  0.639216  0.690196  \n",
       "\n",
       "[7800 rows x 1024 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "normalizer = normalizer.fit(X_train)\n",
    "X_train[X_train.columns[:]] = normalizer.transform(X_train)\n",
    "X_test[X_test.columns[:]] = normalizer.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model can be biased towards numerically larger values if the data is not scaled. If we don't normalize values of features, It may increase the difficulty of the problem being modeled. For exmaple large input values(in this case, pixel values), can result in a model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer from poor performance during learning and sensitivity to input values resulting in higher generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
    "        assert len(data)==len(labels)\n",
    "        self.__n_classes = n_classes\n",
    "        self.__batch_size = batch_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__data = data\n",
    "        self.__onehot_labels = self.__onehot(labels, self.__n_classes)\n",
    "    \n",
    "    def __onehot(self, labels, n_classes):\n",
    "        labels = pd.concat([labels, pd.get_dummies(labels['label'])], axis=1)\n",
    "        onehot_vectors = labels.drop(columns=['label', 'id'])\n",
    "        return onehot_vectors\n",
    "    \n",
    "    def __shuffle_dataset(self):\n",
    "        self.__data, self.__onehot_labels = shuffle(self.__data, self.__onehot_labels)\n",
    "        # self.__data.reset_index(drop=True)\n",
    "        # self.__onehot_labels.reset_index(drop=True)\n",
    "    \n",
    "    def __iter__(self):   \n",
    "        if self.__shuffle:\n",
    "            self.__shuffle_dataset()\n",
    "            \n",
    "        if self.__batch_size==None:\n",
    "            yield (np.matrix(self.__data), np.matrix(self.__onehot_labels))\n",
    "            return\n",
    "            \n",
    "        for idx in range(0, len(self.__data), self.__batch_size):\n",
    "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
    "                   np.matrix(self.__onehot_labels[idx:idx+self.__batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identical:\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "\n",
    "class Relu:\n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        relu_value = np.maximum(matrix, np.zeros(matrix.shape))\n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        relu_derivative = (matrix > 0).astype(float)\n",
    "        return relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class LeakyRelu:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        self.negative_slope = negative_slope\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        slopes = np.zeros(matrix.shape, dtype=float)\n",
    "        slopes[matrix > 0] = 1\n",
    "        slopes[matrix <= 0] = self.negative_slope\n",
    "        return np.multiply(matrix, slopes)\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        leacky_relu_derivative = np.zeros(matrix.shape, dtype=float)\n",
    "        leacky_relu_derivative[matrix > 0] = 1\n",
    "        leacky_relu_derivative[matrix <= 0] = self.negative_slope\n",
    "        return leacky_relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class Sigmoid:\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        sigmoid_value = 1.0/(1.0+np.exp(-matrix))\n",
    "        return sigmoid_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        sigmoid_val = self.__val(matrix)\n",
    "        sigmoid_derivative = np.multiply(sigmoid_val, 1 - sigmoid_val)\n",
    "        return sigmoid_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "class Softmax:    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        softmax_value = np.apply_along_axis(lambda row: np.divide(np.exp(row - np.max(row)), np.sum(np.exp(row - np.max(row)))), 1, matrix)\n",
    "        return softmax_value\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "class Tanh:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        tanh_value = np.divide(np.exp(matrix) - np.exp(-matrix), np.exp(matrix) + np.exp(-matrix))\n",
    "        return tanh_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        tanh_derivative = 1 - np.power(self.__val(matrix), 2)\n",
    "        return tanh_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42745098 0.22745098 0.25490196 ... 0.2        0.18039216 0.27058824]\n",
      " [0.21568627 0.25098039 0.31372549 ... 0.23921569 0.24705882 0.2745098 ]\n",
      " [0.63529412 0.65490196 0.66666667 ... 0.69019608 0.74117647 0.75686275]\n",
      " [0.76078431 0.66666667 0.69411765 ... 0.65490196 0.72156863 0.89019608]\n",
      " [0.2745098  0.25490196 0.24313725 ... 0.59607843 0.63529412 0.65490196]]\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "temp = Dataloader(X_test, y_test, n_classes=2, batch_size=5)\n",
    "itr = iter(temp)\n",
    "ft, lb = next(itr)\n",
    "print(ft)\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We constructed a _temp_ instance of _DataLoader_ and tried for first batch of _temp_. It worked fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing actication Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,11,0.5)\n",
    "fig, axes = plt.subplots(2,2,figsize=(10,10))\n",
    "activation_functions = {'Relu':Relu(), 'LeakyRelu':LeakyRelu(0.2), 'Sigmoid':Sigmoid(), 'Tanh':Tanh()}\n",
    "for ind, f_name in enumerate(list(activation_functions.keys())):\n",
    "    axes[ind//2, ind%2].plot(x, activation_functions[f_name](x))\n",
    "    axes[ind//2, ind%2].set_title(f_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, functions seem to work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy: #(with softmax)\n",
    "    eps = 1e-40\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        softmax_vals = np.clip(Softmax()(true_val), self.eps, 1-self.eps)\n",
    "        cross_entropy_value = np.array(np.sum(np.multiply(expected_val, -np.log2(softmax_vals)), axis=1))\n",
    "        return cross_entropy_value\n",
    "        \n",
    "    def derivative(self, true_val, expected_val):\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        cross_entropy_derivative = Softmax()(true_val) - expected_val\n",
    "        return cross_entropy_derivative\n",
    "    \n",
    "    def __call__(self, true_val, expected_val):\n",
    "        return self.__val(true_val, expected_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
    "  \n",
    "    def __init__(self, input_size, output_size, activation=Identical(), initial_weight='uniform', \n",
    "                 **initializing_parameters):\n",
    "        \n",
    "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
    "        \n",
    "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
    "        \n",
    "        assert initial_weight in self.__weight_initializer_dict, 'Undefined weight initialization function!'\n",
    "\n",
    "\n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "        \n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "        \n",
    "    def forward(self, layer_input):\n",
    "        assert np.ndim(layer_input)==2\n",
    "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
    "        self.__last_input = layer_input\n",
    "        self.__last_activation_input = np.matmul(layer_input, self.weight) + self.bias\n",
    "        self.__last_activation_output = self.activation(self.__last_activation_input)\n",
    "        self.__last_activation_derivative = self.activation.derivative(self.__last_activation_input)\n",
    "        return self.__last_activation_output\n",
    "    \n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "        assert np.ndim(backprop_tensor)==2\n",
    "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
    "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
    "\n",
    "        partial_derivative_E_Z = np.multiply(backprop_tensor, self.__last_activation_derivative)\n",
    "        weights_gradient = np.matmul(np.transpose(self.__last_input), partial_derivative_E_Z)\n",
    "        backprop_tensor = np.matmul(partial_derivative_E_Z, np.transpose(self.__weight))\n",
    "        self.__weight = self.__weight - np.multiply(lr, weights_gradient)\n",
    "\n",
    "        self.__bias = self.__bias - np.divide(np.multiply(lr, np.matmul(np.matrix(np.ones((1,backprop_tensor.shape[0]))), partial_derivative_E_Z)), backprop_tensor.shape[0])\n",
    "\n",
    "        return backprop_tensor\n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
    "        weights = np.matrix(np.random.uniform(low, high, (dim1,dim2)))\n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
    "        weights = np.matrix(np.random.normal(mean, np.sqrt(var), (dim1,dim2)))\n",
    "        return weights\n",
    "    \n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "    \n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "    \n",
    "    @property\n",
    "    def activation(self): return self.__activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "    def __init__(self, input_shape):      \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "    \n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):        \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "    \n",
    "    \n",
    "    def forward(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        network_output = network_input\n",
    "        for layer in self.__layers_list:\n",
    "            network_output = layer.forward(network_output)\n",
    "        \n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):  \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "    \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for ind, (x_train, y_train) in enumerate(trainloader):\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        x_batch = np.matrix(x_batch)\n",
    "        y_batch = np.matrix(y_batch)\n",
    "        network_output = self.forward(x_batch)\n",
    "        batch_average_loss = np.mean(self.__loss(network_output, y_batch))\n",
    "        batch_accuracy = self.__compute_accuracy(network_output, y_batch)\n",
    "\n",
    "        self.__update_weights(network_output, y_batch)\n",
    "\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "        \n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        x_batch = np.matrix(x_batch)\n",
    "        y_batch = np.matrix(y_batch)\n",
    "        network_output = self.forward(x_batch)\n",
    "        batch_average_loss = np.mean(self.__loss(network_output, y_batch))\n",
    "        batch_accuracy = self.__compute_accuracy(network_output, y_batch)\n",
    "\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "            \n",
    "        \n",
    "    def __get_labels(self, outputs):\n",
    "        def f(row):\n",
    "            base_row = np.zeros(outputs.shape[1], dtype=int)\n",
    "            base_row[np.argmax(row)] = 1\n",
    "            return base_row\n",
    "        labels = np.apply_along_axis(f, 1, outputs)\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        accuracy = 100.0 * np.sum(np.multiply(self.__get_labels(output), expected_output)) / output.shape[0]\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "        backprop_tensor = self.__loss.derivative(output, y_train)\n",
    "        for layer in reversed(self.__layers_list):\n",
    "            backprop_tensor = layer.update_weights(backprop_tensor, self.__lr)\n",
    "        return\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        return self.__test(input_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 61.193647540983605\tAverage Loss: 1.0145657844766753\n",
      "\tTest: Average Accuracy: 64.9090909090909\tAverage Loss: 0.8867181797617029\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 67.35826502732239\tAverage Loss: 0.8693689760624256\n",
      "\tTest: Average Accuracy: 69.68181818181819\tAverage Loss: 0.8347329024176174\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 69.90266393442623\tAverage Loss: 0.825693649515658\n",
      "\tTest: Average Accuracy: 71.27272727272727\tAverage Loss: 0.8051366389549456\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 71.5548155737705\tAverage Loss: 0.7922658897625954\n",
      "\tTest: Average Accuracy: 72.4090909090909\tAverage Loss: 0.7881713439382734\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 72.89959016393442\tAverage Loss: 0.7691979920603884\n",
      "\tTest: Average Accuracy: 72.81818181818181\tAverage Loss: 0.7892561562308978\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 74.06933060109289\tAverage Loss: 0.74971524131888\n",
      "\tTest: Average Accuracy: 72.54545454545455\tAverage Loss: 0.7792517298550441\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 75.50375683060108\tAverage Loss: 0.7304182267693641\n",
      "\tTest: Average Accuracy: 73.5909090909091\tAverage Loss: 0.7743390819792811\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 76.0160519125683\tAverage Loss: 0.7112354109134733\n",
      "\tTest: Average Accuracy: 73.5909090909091\tAverage Loss: 0.7651737830152369\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 76.94245218579236\tAverage Loss: 0.6944624466479355\n",
      "\tTest: Average Accuracy: 73.9090909090909\tAverage Loss: 0.7643514595971366\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 77.95850409836065\tAverage Loss: 0.6770303491547272\n",
      "\tTest: Average Accuracy: 74.36363636363636\tAverage Loss: 0.7630530415032988\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 78.8123292349727\tAverage Loss: 0.6583487285732381\n",
      "\tTest: Average Accuracy: 75.13636363636364\tAverage Loss: 0.7525534010364953\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 79.41854508196721\tAverage Loss: 0.6410890997223663\n",
      "\tTest: Average Accuracy: 74.95454545454545\tAverage Loss: 0.7692665310007233\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 80.16137295081967\tAverage Loss: 0.6250707848482161\n",
      "\tTest: Average Accuracy: 74.72727272727273\tAverage Loss: 0.7530579195922816\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 80.58401639344262\tAverage Loss: 0.6078466997811892\n",
      "\tTest: Average Accuracy: 74.9090909090909\tAverage Loss: 0.7764876902146614\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 81.28842213114754\tAverage Loss: 0.592986801675207\n",
      "\tTest: Average Accuracy: 75.13636363636364\tAverage Loss: 0.7795807726001646\n"
     ]
    }
   ],
   "source": [
    "# Sample code for building and training a model\n",
    "\n",
    "INPUT_SHAPE = df.shape[1]\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "TRAINLOADER = Dataloader(X_train, y_train, 2, BATCH_SIZE, shuffle=False)\n",
    "TESTLOADER = Dataloader(X_test, y_test, 2, batch_size=y_test.shape[0])\n",
    "INITIAL_WEIGHTS_PARAM = {'low':0, 'high':0.05, 'mean': 0, 'var': 0.04 }\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) Weights impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 50.11953551912569\tAverage Loss: 1.0000085736810542\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.000017791603549\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 1.0000045495699\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000339833688117\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 1.000001381941032\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000486629242789\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999988870347519\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000619286565873\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999969206888412\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000738839645686\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999953697860758\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000846331501325\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999941455512017\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0000942785464306\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999931782971868\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.000102918575433\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999924133071805\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001106464983167\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999918076064745\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.000117549677358\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999913274319338\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001237092108695\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999909462480401\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001291998359043\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999906431913316\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001340900190547\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999904018506102\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001384421754134\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 50.27322404371585\tAverage Loss: 0.9999902093103278\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 1.0001423129709714\n"
     ]
    }
   ],
   "source": [
    "INITIAL_WEIGHTS_PARAM = {'low':0, 'high':0, 'mean': 0, 'var':0.04 }\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Relu(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Relu(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)\n",
    "INITIAL_WEIGHTS_PARAM = {'low':0, 'high':0.05, 'mean': 0, 'var':0.04 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in the former model which its initial weights were not zero at first, we've got better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3) Finding Best learning-rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After so many trail and error, best learning rate that was discovered is __0.001__ with initial weights from normal disturbution. Since this value is as same as defualt value, we just show the results of __LR * 10__ and __LR * 0.1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 49.64993169398907\tAverage Loss: 7.17453503810743\n",
      "\tTest: Average Accuracy: 51.13636363636363\tAverage Loss: 0.9983759016009945\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 49.32974726775956\tAverage Loss: 0.9998136501842094\n",
      "\tTest: Average Accuracy: 51.13636363636363\tAverage Loss: 0.9985685041372935\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 49.594433060109296\tAverage Loss: 0.9995903210131628\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9986960773368674\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 49.86338797814208\tAverage Loss: 0.9995650518559126\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987385580727763\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 49.965846994535525\tAverage Loss: 0.9994683329597089\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.998749994784183\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9994525911906763\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987530700388985\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9994484089682721\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987538874762631\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 49.965846994535525\tAverage Loss: 1.0036158580401875\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987492957833206\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995691975080155\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.998755744470149\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995689198124238\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987576527040615\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995688413692541\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987582154982213\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995688185483507\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987583813160427\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995688118442376\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987584301520327\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995688098641246\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.9987584445283639\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 50.04269125683061\tAverage Loss: 0.9995688092735585\n",
      "\tTest: Average Accuracy: 49.0\tAverage Loss: 0.998758448754968\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001 * 10\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 53.90198087431693\tAverage Loss: 1.056028577801528\n",
      "\tTest: Average Accuracy: 62.40909090909091\tAverage Loss: 0.9445149492029151\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 58.40590846994536\tAverage Loss: 0.9824355526021297\n",
      "\tTest: Average Accuracy: 64.0\tAverage Loss: 0.9259996406631733\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 60.77954234972677\tAverage Loss: 0.9531678817652479\n",
      "\tTest: Average Accuracy: 64.9090909090909\tAverage Loss: 0.9100059483282311\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 62.713456284153\tAverage Loss: 0.931662971842284\n",
      "\tTest: Average Accuracy: 66.04545454545455\tAverage Loss: 0.8952595617749943\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 64.05823087431693\tAverage Loss: 0.9133033675608083\n",
      "\tTest: Average Accuracy: 66.95454545454545\tAverage Loss: 0.8815159206038915\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 65.4755806010929\tAverage Loss: 0.8961069421226701\n",
      "\tTest: Average Accuracy: 67.5\tAverage Loss: 0.8681796438375882\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 66.56847677595628\tAverage Loss: 0.8803593741858102\n",
      "\tTest: Average Accuracy: 67.77272727272727\tAverage Loss: 0.857093284477858\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 67.59306693989072\tAverage Loss: 0.8662412653085582\n",
      "\tTest: Average Accuracy: 68.81818181818181\tAverage Loss: 0.8469383257047068\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 68.46396857923499\tAverage Loss: 0.8537460885886603\n",
      "\tTest: Average Accuracy: 69.22727272727273\tAverage Loss: 0.8380702256453335\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 69.14275956284153\tAverage Loss: 0.8423225137112956\n",
      "\tTest: Average Accuracy: 70.0909090909091\tAverage Loss: 0.8298870172180443\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 69.70628415300547\tAverage Loss: 0.8316633250192603\n",
      "\tTest: Average Accuracy: 70.36363636363636\tAverage Loss: 0.8232667441871515\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 70.38507513661203\tAverage Loss: 0.8223337686341826\n",
      "\tTest: Average Accuracy: 70.63636363636364\tAverage Loss: 0.8173555242906888\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 70.87175546448088\tAverage Loss: 0.8141470162797227\n",
      "\tTest: Average Accuracy: 70.63636363636364\tAverage Loss: 0.8123926337313083\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 71.3200136612022\tAverage Loss: 0.8064662071122678\n",
      "\tTest: Average Accuracy: 71.18181818181819\tAverage Loss: 0.8076906067372683\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 71.69142759562843\tAverage Loss: 0.7994149500187345\n",
      "\tTest: Average Accuracy: 71.45454545454545\tAverage Loss: 0.8039272680853409\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001 * 0.1\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Relu(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we choose learning rate to be high, this may cause the model to converge too quickly and we may end in a suboptimal solution. As we know, learning rate effect on step size of getting close to optimal solution. If learning rate is too high, the model will can jump over optimal point which known as __overshooting__.\n",
    "\n",
    "\n",
    "If we choose learning rate to be low, this may cause the model never converge or get stuck on a suboptimal solution. Also in this case, because step size is very small, the model will be slow.\n",
    "\n",
    "Here we can see that if we choose __LR * 10__ we can imporve our accuracy and the model have kind of overshooting problem.\n",
    "\n",
    "And in __LR * 0.1__ case, the model is slow such that in 15 epochs has less accuracy than when we used LR itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 53.581796448087424\tAverage Loss: 0.9933521060613116\n",
      "\tTest: Average Accuracy: 56.63636363636363\tAverage Loss: 0.9770669080757641\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 58.37175546448087\tAverage Loss: 0.97615964004572\n",
      "\tTest: Average Accuracy: 59.27272727272727\tAverage Loss: 0.9600234465041575\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 59.720799180327866\tAverage Loss: 0.9644092113700328\n",
      "\tTest: Average Accuracy: 60.54545454545455\tAverage Loss: 0.9461724639032879\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 60.76246584699454\tAverage Loss: 0.9534594483033899\n",
      "\tTest: Average Accuracy: 61.77272727272727\tAverage Loss: 0.9325457079988907\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 61.90659153005464\tAverage Loss: 0.9419410416844322\n",
      "\tTest: Average Accuracy: 63.72727272727273\tAverage Loss: 0.918390815910262\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 62.87995218579235\tAverage Loss: 0.9299184241838493\n",
      "\tTest: Average Accuracy: 65.04545454545455\tAverage Loss: 0.9039950164491259\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 63.725239071038246\tAverage Loss: 0.9178243510682977\n",
      "\tTest: Average Accuracy: 66.68181818181819\tAverage Loss: 0.8899908327146013\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 65.01878415300546\tAverage Loss: 0.9061226404086774\n",
      "\tTest: Average Accuracy: 67.0\tAverage Loss: 0.8769821611015629\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 65.90249316939891\tAverage Loss: 0.8951176837653999\n",
      "\tTest: Average Accuracy: 67.63636363636364\tAverage Loss: 0.8652198476048168\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 66.45321038251366\tAverage Loss: 0.8848111839063201\n",
      "\tTest: Average Accuracy: 68.31818181818181\tAverage Loss: 0.8545863667633778\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 66.80754781420765\tAverage Loss: 0.8749937605951063\n",
      "\tTest: Average Accuracy: 68.86363636363636\tAverage Loss: 0.8448112315642496\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 67.35826502732239\tAverage Loss: 0.865441748520429\n",
      "\tTest: Average Accuracy: 69.13636363636364\tAverage Loss: 0.8356552805746519\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 67.97301912568305\tAverage Loss: 0.8560398344673757\n",
      "\tTest: Average Accuracy: 69.5\tAverage Loss: 0.8269684441121066\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 68.44689207650272\tAverage Loss: 0.846775941839861\n",
      "\tTest: Average Accuracy: 70.36363636363636\tAverage Loss: 0.8186722787969776\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 68.75853825136613\tAverage Loss: 0.8376845890637866\n",
      "\tTest: Average Accuracy: 71.04545454545455\tAverage Loss: 0.8107359489526784\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Sigmoid(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Sigmoid(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 61.240607923497265\tAverage Loss: 0.9454969143936932\n",
      "\tTest: Average Accuracy: 65.13636363636364\tAverage Loss: 0.8884924400875306\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 66.31232923497268\tAverage Loss: 0.8784201471683938\n",
      "\tTest: Average Accuracy: 68.22727272727273\tAverage Loss: 0.8328922323033802\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 69.18971994535518\tAverage Loss: 0.8345455198014144\n",
      "\tTest: Average Accuracy: 70.72727272727273\tAverage Loss: 0.8037183580547386\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 71.01263661202186\tAverage Loss: 0.8014131446555621\n",
      "\tTest: Average Accuracy: 71.72727272727273\tAverage Loss: 0.7839468446435783\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 72.63917349726776\tAverage Loss: 0.7740498401896896\n",
      "\tTest: Average Accuracy: 72.54545454545455\tAverage Loss: 0.7695952926282319\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 73.9839480874317\tAverage Loss: 0.7494927792033615\n",
      "\tTest: Average Accuracy: 73.27272727272727\tAverage Loss: 0.7597877588720313\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 75.14088114754098\tAverage Loss: 0.727210612026428\n",
      "\tTest: Average Accuracy: 74.13636363636364\tAverage Loss: 0.7534174713773908\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 76.20389344262296\tAverage Loss: 0.7067589514033727\n",
      "\tTest: Average Accuracy: 74.0\tAverage Loss: 0.7488007384052925\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 77.03637295081967\tAverage Loss: 0.687453700040034\n",
      "\tTest: Average Accuracy: 74.0\tAverage Loss: 0.7454299160578869\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 77.92862021857924\tAverage Loss: 0.668915686048621\n",
      "\tTest: Average Accuracy: 74.27272727272727\tAverage Loss: 0.7438311551860427\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 78.8635587431694\tAverage Loss: 0.6509247675055324\n",
      "\tTest: Average Accuracy: 74.13636363636364\tAverage Loss: 0.7442885677819526\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 79.58077185792351\tAverage Loss: 0.6332898361272351\n",
      "\tTest: Average Accuracy: 73.95454545454545\tAverage Loss: 0.7465190036737733\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 80.25102459016394\tAverage Loss: 0.6160040594629762\n",
      "\tTest: Average Accuracy: 74.04545454545455\tAverage Loss: 0.7501273548224654\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 80.82735655737704\tAverage Loss: 0.5990310305926442\n",
      "\tTest: Average Accuracy: 73.95454545454545\tAverage Loss: 0.7548842262463499\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 81.53176229508196\tAverage Loss: 0.5822640906428646\n",
      "\tTest: Average Accuracy: 74.18181818181819\tAverage Loss: 0.7605750535437987\n"
     ]
    }
   ],
   "source": [
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=Tanh(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=64, activation=Tanh(), initial_weight='normal', **INITIAL_WEIGHTS_PARAM)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeakyRelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 62.807377049180324\tAverage Loss: 1.0640771644010905\n",
      "\tTest: Average Accuracy: 68.36363636363636\tAverage Loss: 0.8460988233254527\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 67.84494535519124\tAverage Loss: 0.8657578420525482\n",
      "\tTest: Average Accuracy: 71.63636363636364\tAverage Loss: 0.8081784408238194\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 70.15454234972678\tAverage Loss: 0.8298290892159028\n",
      "\tTest: Average Accuracy: 73.68181818181819\tAverage Loss: 0.7863897665839641\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 71.97745901639344\tAverage Loss: 0.8011569664326906\n",
      "\tTest: Average Accuracy: 73.22727272727273\tAverage Loss: 0.7750732484627729\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 73.23685109289616\tAverage Loss: 0.7752774789604396\n",
      "\tTest: Average Accuracy: 73.63636363636364\tAverage Loss: 0.7668108349092132\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 74.5090505464481\tAverage Loss: 0.7540538557187229\n",
      "\tTest: Average Accuracy: 74.77272727272727\tAverage Loss: 0.7542375401336973\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 75.37568306010928\tAverage Loss: 0.7334635097164225\n",
      "\tTest: Average Accuracy: 75.27272727272727\tAverage Loss: 0.7484817585408762\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 76.05020491803279\tAverage Loss: 0.7140529383377912\n",
      "\tTest: Average Accuracy: 75.5\tAverage Loss: 0.743144302594847\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 76.69057377049181\tAverage Loss: 0.6961403465924898\n",
      "\tTest: Average Accuracy: 76.04545454545455\tAverage Loss: 0.7381737574861031\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 77.5785519125683\tAverage Loss: 0.6773388244055718\n",
      "\tTest: Average Accuracy: 76.13636363636364\tAverage Loss: 0.7337939389659389\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 78.35553278688525\tAverage Loss: 0.6576929988533741\n",
      "\tTest: Average Accuracy: 76.04545454545455\tAverage Loss: 0.7291531595319587\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 79.1410519125683\tAverage Loss: 0.6404099625692832\n",
      "\tTest: Average Accuracy: 76.63636363636364\tAverage Loss: 0.7272339414578207\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 79.77288251366122\tAverage Loss: 0.6241096165229799\n",
      "\tTest: Average Accuracy: 76.63636363636364\tAverage Loss: 0.7264856945821204\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 80.22967896174862\tAverage Loss: 0.607382530637076\n",
      "\tTest: Average Accuracy: 76.0909090909091\tAverage Loss: 0.7270312520567526\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 80.99812158469945\tAverage Loss: 0.5878136909417633\n",
      "\tTest: Average Accuracy: 76.27272727272727\tAverage Loss: 0.7305721106868504\n"
     ]
    }
   ],
   "source": [
    "INITIAL_WEIGHTS_PARAM2 = {'low':-0.1, 'high':0.1, 'mean': 0, 'var':0.04 }\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=64, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tanh__ and __Sogmoid__ functions map input to output od range [-1,1] or [0,1] which may not be good in this model. Also, if we give bigger inputs to these functions, we get smaller derivative values; in fact, most derivative value that these funcions can give is less or equal to 1. So as we go deep in layers of model with lots of neurons, derivative values and also outpus of functions become smaller and smaller(as they multiply to getter) which not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LeakyRelu__ function in contrast to __Leaky__ does not ignore negative values which is good and fixes __dying ReLU__ problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BachSize=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 50.52564102564103\tAverage Loss: 7.648006374048397\n",
      "\tTest: Average Accuracy: 54.18181818181818\tAverage Loss: 0.9949680181364562\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 55.3974358974359\tAverage Loss: 0.9911299904560149\n",
      "\tTest: Average Accuracy: 57.31818181818182\tAverage Loss: 0.9800588229341346\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 58.02564102564102\tAverage Loss: 0.9786488110134163\n",
      "\tTest: Average Accuracy: 59.54545454545455\tAverage Loss: 0.9708286530709205\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 59.02564102564102\tAverage Loss: 0.9707816896760963\n",
      "\tTest: Average Accuracy: 60.68181818181818\tAverage Loss: 0.9638305962358469\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 59.26923076923077\tAverage Loss: 0.964652621789868\n",
      "\tTest: Average Accuracy: 60.81818181818182\tAverage Loss: 0.9559096014802951\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 60.26923076923076\tAverage Loss: 0.9596782488815698\n",
      "\tTest: Average Accuracy: 61.86363636363637\tAverage Loss: 0.9506135794851135\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 60.65384615384615\tAverage Loss: 0.9555559576091659\n",
      "\tTest: Average Accuracy: 62.59090909090909\tAverage Loss: 0.9454707286461429\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 61.14102564102564\tAverage Loss: 0.9517848291967457\n",
      "\tTest: Average Accuracy: 62.5\tAverage Loss: 0.9408285684644061\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 61.55128205128205\tAverage Loss: 0.9474896394585154\n",
      "\tTest: Average Accuracy: 62.31818181818182\tAverage Loss: 0.9367758300004274\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 61.384615384615394\tAverage Loss: 0.9541591207128384\n",
      "\tTest: Average Accuracy: 63.45454545454545\tAverage Loss: 0.9332354970248161\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 62.06410256410257\tAverage Loss: 0.9408220007684613\n",
      "\tTest: Average Accuracy: 63.59090909090909\tAverage Loss: 0.932669659331395\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 62.871794871794876\tAverage Loss: 0.9373605150975627\n",
      "\tTest: Average Accuracy: 63.90909090909091\tAverage Loss: 0.924485366698167\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 62.84615384615385\tAverage Loss: 0.9341766396376419\n",
      "\tTest: Average Accuracy: 64.95454545454545\tAverage Loss: 0.9212267005498693\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 63.128205128205124\tAverage Loss: 0.9306491662296268\n",
      "\tTest: Average Accuracy: 64.95454545454545\tAverage Loss: 0.9171252906746746\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 63.53846153846154\tAverage Loss: 0.9288449532418297\n",
      "\tTest: Average Accuracy: 65.4090909090909\tAverage Loss: 0.9144235570328693\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 150\n",
    "TRAINLOADER = Dataloader(X_train, y_train, 2, BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(X_test, y_test, 2, batch_size=y_test.shape[0])\n",
    "INITIAL_WEIGHTS_PARAM2 = {'low':-0.1, 'high':0.1, 'mean': 0, 'var':0.04 }\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=64, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, because batch size is little large, it seems, the number of iterations that model will do to updates its weights is not enough and we don't get good accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BachSize=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 62.44877049180328\tAverage Loss: 0.9858845119635454\n",
      "\tTest: Average Accuracy: 66.0\tAverage Loss: 0.8840457507267931\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 67.7126024590164\tAverage Loss: 0.8704806815946446\n",
      "\tTest: Average Accuracy: 70.68181818181819\tAverage Loss: 0.8216777721052898\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 69.24948770491804\tAverage Loss: 0.8346070630886048\n",
      "\tTest: Average Accuracy: 69.4090909090909\tAverage Loss: 0.8704135560503358\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 71.31147540983606\tAverage Loss: 0.80175492679515\n",
      "\tTest: Average Accuracy: 72.54545454545455\tAverage Loss: 0.790954671288196\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 72.47694672131148\tAverage Loss: 0.7806264596952217\n",
      "\tTest: Average Accuracy: 68.63636363636364\tAverage Loss: 0.8682498508089367\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 73.53995901639344\tAverage Loss: 0.7580089402835912\n",
      "\tTest: Average Accuracy: 74.22727272727273\tAverage Loss: 0.7696177553447323\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 74.59016393442623\tAverage Loss: 0.7380891600599832\n",
      "\tTest: Average Accuracy: 74.54545454545455\tAverage Loss: 0.755638441139038\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 75.7172131147541\tAverage Loss: 0.7209316481746788\n",
      "\tTest: Average Accuracy: 74.22727272727273\tAverage Loss: 0.7707746457082709\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 76.38319672131148\tAverage Loss: 0.7024572309965639\n",
      "\tTest: Average Accuracy: 75.54545454545455\tAverage Loss: 0.7514456375248936\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 77.30532786885246\tAverage Loss: 0.6819248349171384\n",
      "\tTest: Average Accuracy: 74.95454545454545\tAverage Loss: 0.7691723199262084\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 77.88165983606558\tAverage Loss: 0.6681134074393339\n",
      "\tTest: Average Accuracy: 74.81818181818181\tAverage Loss: 0.7676651487714189\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 78.43237704918033\tAverage Loss: 0.6559458449507461\n",
      "\tTest: Average Accuracy: 75.22727272727273\tAverage Loss: 0.7486105423448957\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 79.38012295081967\tAverage Loss: 0.6358449420726475\n",
      "\tTest: Average Accuracy: 75.5909090909091\tAverage Loss: 0.7626430790357989\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 79.53381147540983\tAverage Loss: 0.6209931531183465\n",
      "\tTest: Average Accuracy: 75.86363636363636\tAverage Loss: 0.7480963954672448\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 80.39190573770492\tAverage Loss: 0.6037758119254385\n",
      "\tTest: Average Accuracy: 75.68181818181819\tAverage Loss: 0.7653647788504441\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "TRAINLOADER = Dataloader(X_train, y_train, 2, BATCH_SIZE, shuffle=True)\n",
    "TESTLOADER = Dataloader(X_test, y_test, 2, batch_size=y_test.shape[0])\n",
    "INITIAL_WEIGHTS_PARAM2 = {'low':-0.1, 'high':0.1, 'mean': 0, 'var':0.04 }\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=64, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, It seems batch size of 16 does not make that mush difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With help of batches, Training model requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n",
    "\n",
    "A smaller batch size, increases the number of forward/backward propagations, leading to a slower neural network. Also it leads to a higher variance, due to smaller number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 62.056010928961754\tAverage Loss: 1.0729086970383708\n",
      "\tTest: Average Accuracy: 67.63636363636364\tAverage Loss: 0.8611554501539194\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 67.32411202185793\tAverage Loss: 0.8612925468353287\n",
      "\tTest: Average Accuracy: 70.68181818181819\tAverage Loss: 0.8058248341921902\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 70.21431010928961\tAverage Loss: 0.8168470266370591\n",
      "\tTest: Average Accuracy: 71.68181818181819\tAverage Loss: 0.782380203270243\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 71.53346994535518\tAverage Loss: 0.7881984063154817\n",
      "\tTest: Average Accuracy: 72.27272727272727\tAverage Loss: 0.7692486323320096\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 73.03193306010928\tAverage Loss: 0.7652326472492601\n",
      "\tTest: Average Accuracy: 73.31818181818181\tAverage Loss: 0.7599643595883541\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 74.13763661202186\tAverage Loss: 0.7447416244753912\n",
      "\tTest: Average Accuracy: 74.54545454545455\tAverage Loss: 0.7486176854206906\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 74.96157786885246\tAverage Loss: 0.7246158860496906\n",
      "\tTest: Average Accuracy: 75.0\tAverage Loss: 0.7478078939569787\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 75.9434767759563\tAverage Loss: 0.7083196283590131\n",
      "\tTest: Average Accuracy: 75.22727272727273\tAverage Loss: 0.739725258590347\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 76.47711748633878\tAverage Loss: 0.6910651493316189\n",
      "\tTest: Average Accuracy: 75.63636363636364\tAverage Loss: 0.7380640905942817\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 77.12175546448088\tAverage Loss: 0.6731070968989592\n",
      "\tTest: Average Accuracy: 76.22727272727273\tAverage Loss: 0.7336826414366491\n",
      "Epoch 11:\n",
      "\tTrain: Average Accuracy: 78.05669398907105\tAverage Loss: 0.6563980003346545\n",
      "\tTest: Average Accuracy: 75.9090909090909\tAverage Loss: 0.7300293736655871\n",
      "Epoch 12:\n",
      "\tTrain: Average Accuracy: 78.97882513661203\tAverage Loss: 0.638876618816102\n",
      "\tTest: Average Accuracy: 76.54545454545455\tAverage Loss: 0.7304895565889796\n",
      "Epoch 13:\n",
      "\tTrain: Average Accuracy: 79.67042349726776\tAverage Loss: 0.6221547630913824\n",
      "\tTest: Average Accuracy: 76.5909090909091\tAverage Loss: 0.7337788979071164\n",
      "Epoch 14:\n",
      "\tTrain: Average Accuracy: 80.30225409836065\tAverage Loss: 0.606825586760866\n",
      "\tTest: Average Accuracy: 76.18181818181819\tAverage Loss: 0.7392284625003686\n",
      "Epoch 15:\n",
      "\tTrain: Average Accuracy: 81.12192622950819\tAverage Loss: 0.5904711310141932\n",
      "\tTest: Average Accuracy: 75.72727272727273\tAverage Loss: 0.7428979143841299\n",
      "Epoch 16:\n",
      "\tTrain: Average Accuracy: 81.46772540983606\tAverage Loss: 0.5739193839432267\n",
      "\tTest: Average Accuracy: 76.81818181818181\tAverage Loss: 0.7502135243925016\n",
      "Epoch 17:\n",
      "\tTrain: Average Accuracy: 82.35997267759564\tAverage Loss: 0.5551621813692106\n",
      "\tTest: Average Accuracy: 77.18181818181819\tAverage Loss: 0.7486777224875149\n",
      "Epoch 18:\n",
      "\tTrain: Average Accuracy: 82.7484631147541\tAverage Loss: 0.5414943428429727\n",
      "\tTest: Average Accuracy: 76.77272727272727\tAverage Loss: 0.7636585707788299\n",
      "Epoch 19:\n",
      "\tTrain: Average Accuracy: 83.21379781420764\tAverage Loss: 0.5244598445655855\n",
      "\tTest: Average Accuracy: 76.81818181818181\tAverage Loss: 0.7691400898535385\n",
      "Epoch 20:\n",
      "\tTrain: Average Accuracy: 84.09750683060108\tAverage Loss: 0.5069513097984815\n",
      "\tTest: Average Accuracy: 76.63636363636364\tAverage Loss: 0.7797143028186848\n",
      "Epoch 21:\n",
      "\tTrain: Average Accuracy: 84.44330601092895\tAverage Loss: 0.491396562556731\n",
      "\tTest: Average Accuracy: 76.63636363636364\tAverage Loss: 0.785133386923127\n",
      "Epoch 22:\n",
      "\tTrain: Average Accuracy: 85.33982240437157\tAverage Loss: 0.47881379904570565\n",
      "\tTest: Average Accuracy: 77.04545454545455\tAverage Loss: 0.8072353732707466\n",
      "Epoch 23:\n",
      "\tTrain: Average Accuracy: 85.94603825136613\tAverage Loss: 0.4604235436499193\n",
      "\tTest: Average Accuracy: 76.4090909090909\tAverage Loss: 0.8276310103141767\n",
      "Epoch 24:\n",
      "\tTrain: Average Accuracy: 86.51810109289616\tAverage Loss: 0.44534740253775257\n",
      "\tTest: Average Accuracy: 76.68181818181819\tAverage Loss: 0.8249904738506244\n",
      "Epoch 25:\n",
      "\tTrain: Average Accuracy: 87.22250683060108\tAverage Loss: 0.43021374822680947\n",
      "\tTest: Average Accuracy: 76.0909090909091\tAverage Loss: 0.8462587532209129\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = df.shape[1]\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "TRAINLOADER = Dataloader(X_train, y_train, 2, BATCH_SIZE, shuffle=False)\n",
    "TESTLOADER = Dataloader(X_test, y_test, 2, batch_size=y_test.shape[0])\n",
    "INITIAL_WEIGHTS_PARAM2 = {'low':-0.1, 'high':0.1, 'mean': 0, 'var':0.04 }\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons=256, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=64, activation=LeakyRelu(0.001), initial_weight='normal', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.add_layer(n_neurons=2, activation=Identical(), initial_weight='uniform', **INITIAL_WEIGHTS_PARAM2)\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
